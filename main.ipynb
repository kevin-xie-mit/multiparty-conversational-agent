{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from uuid import uuid4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_num(file_name):\n",
    "\n",
    "    group_num = file_name.split(\"_\")[1].split(\".\")[0]\n",
    "\n",
    "    return int(group_num)\n",
    "\n",
    "def split_text(text):\n",
    "    \"\"\"\n",
    "    Splits text into [time, person, text]\n",
    "    \"\"\"\n",
    "\n",
    "    time = text.split(\" - \")[0]\n",
    "    person = text.split(\" - \")[1].split(\":\")[0]\n",
    "    text = text.split(\" - \")[1].split(\":\")[1].strip()\n",
    "\n",
    "    return time, person, text\n",
    "\n",
    "\n",
    "def create_vector_store():\n",
    "    \"\"\"\n",
    "    Create a vector store using Chroma\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = Chroma(\n",
    "        collection_name=str(uuid4()),  # unique collection name for each call\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=os.getenv(\"PERSIST_DIRECTORY\")\n",
    "    )\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"\n",
    "You are responsible for facilitating an online text-based group discussion within a decision-making process.\n",
    "   \n",
    "The goal of the group conversation is to reach a single, shared decision among three human participants on a given problem\n",
    "within a  within a 30-minute session.    \n",
    "\n",
    "The problem is to solve a fictional murder mystery by deciding which of the three suspects— Eddie Sullivan (handyman),\n",
    "Billy Prentice (yardman), or Mickey Malone (business partner) —is the culprit.  \n",
    "\n",
    "Only one of the three suspects is guilty.  Before the discussion begins, each group member receives and reviews slightly \n",
    "different versions of an interview document containing evidence about the murder case. Each participant’s document contains \n",
    "some shared information available to all members and some unique information that only they have. Participants are not allowed \n",
    "to review the interview document again or receive any additional factual information about the murder during the discussion \n",
    "session. You do not know the content of the interviews. Participants are informed that the moderator is an AI agent.    \n",
    "Participants must decide on the correct culprit during this session, as there will be no further discussion afterward.\n",
    "\n",
    "The conversation is conducted in Italian. \n",
    "\n",
    "Your role, as the moderator, is to facilitate communication without being intrusive. You should only intervene in the following \n",
    "cases: \n",
    "\n",
    "- If one speaker dominates the conversation, encourage quieter members to contribute. Participants have a higher chance of \n",
    "correctly identifying the culprit if they successfully share all their unique information. \n",
    "- If the discussion goes off-topic, remind participants to stay focused on the main goal of the conversation.     \n",
    "- If participants are disrespectful or using inappropriate language,  ensure a civil and constructive discussion. \n",
    "- If there are disagreements or misunderstandings between participants, acknowledge different viewpoints and integrate and \n",
    "summarize all key points discussed.\n",
    "\n",
    "Encourage participants to focus on the correct solution rather than on the consensus.  \n",
    "\n",
    "Never push participants—implicitly or explicitly—toward specific interpretations or solutions and never decide for them.  \n",
    "Output formatting:Please always respond via a JSON file that contains a flag INTERVENE and a TEXT field. In case you, as the moderator, have to intervene within the chat conversation,\n",
    "set the INTERVENE flag to true and add your answer in the TEXT field. Make sure both fields are always distinct and INTERVENE is only true or false.\n",
    "If as a moderator you don't intervene, set INTERVENE to false and place in TEXT your reasoning.\n",
    "Here is some examples of a JSON files: {\\\"INTERVENE\\\": false, \\\"TEXT\\\": \\\"La conversazione si sta sviluppando in modo organico, non è necessario il mio intervento.\\\"},\n",
    "{\\\"INTERVENE\\\": true, \\\"TEXT\\\": \\\"*message to send*\\\"}\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = \"/Users/kevinxie/Desktop/MIT/multiparty-conversational-agent/New_IDS_Chat (Old studies)\"\n",
    "\n",
    "group_files = os.listdir(txt_path)\n",
    "group_files.remove(\".DS_Store\")\n",
    "group_files = sorted(group_files, key=get_group_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "functions = [\n",
    "    {\"name\": \"intervene\",\n",
    "    \"description\": \"Given the following context, consisting of the most recent messages and relevant context from past messages, determine whether you need to intervene at this point in the conversation\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"intervene\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"True if you need to intervene, False otherwise\"\n",
    "            },\n",
    "            \"reasoning\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The reasoning for your decision in English\"\n",
    "            },\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"If you do want to intervene, return the message you want to send to the participants in English. Otherwise, return an empty string.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"intervene\"]\n",
    "\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# response.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_13.txt\n",
      "B\n",
      "A\n",
      "C\n",
      "B\n",
      "B\n",
      "A\n",
      "C\n",
      "B\n",
      "A\n",
      "M\n",
      "CONTEXT: Who do you think did it\n",
      "I believe it was Billy\n",
      "I think it might have been Eddie Sullivan as it was his crowbar\n",
      "I agree that it was Billy\n",
      "But it would make sense that he had a crowbar because he is a handyman\n",
      "That's also true\n",
      "Billy was behaving weirdly and giving confusing answers and can't handle his money\n",
      "maybe the victim refused to give him the advance he wanted and he got angry\n",
      "Yes he seemed \"lost for words\"\n",
      "There seems to be a disagreement between you about who the culprit is. Please try to listen to each other's points of view and provide evidence to support your claims. Let's avoid assumptions and personal attacks.\n",
      "Who do you think did it\n",
      "maybe the victim refused to give him the advance he wanted and he got angry\n",
      "Billy was behaving weirdly and giving confusing answers and can't handle his money\n",
      "That's also true\n",
      "I agree that it was Billy\n"
     ]
    }
   ],
   "source": [
    "group_13 = group_files[12]\n",
    "print(group_13)\n",
    "\n",
    "with open(os.path.join(txt_path, group_13), \"r\") as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "vector_store = create_vector_store()\n",
    "\n",
    "all_messages = []\n",
    "for line in text:\n",
    "    time, person, text = split_text(line)\n",
    "\n",
    "    all_messages.append(line)\n",
    "\n",
    "    print(person)\n",
    "    if person == \"M\":\n",
    "        # Multi-layer RAG\n",
    "        # 1. Retrieve the most recent k messages\n",
    "        # 2. Semantic relevance\n",
    "        # 3. Player-specific context --> dynamically generate running context of each player and what they are like\n",
    "        # 4. Game State --> current state of the game, rules, and discovered clues\n",
    "\n",
    "        context = \"\\n\".join(all_messages[-10:])\n",
    "\n",
    "        # 5 most relevant documents\n",
    "        for doc in vector_store.similarity_search(PROMPT, k=5):\n",
    "            context += \"\\n\" + doc.page_content\n",
    "\n",
    "        print(\"CONTEXT:\", context)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-0613\",\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": context}\n",
    "            ],\n",
    "            functions=functions,\n",
    "            function_call={\"name\": \"intervene\"},\n",
    "        )\n",
    "        \n",
    "        # Need to append the text!\n",
    "        with open(os.path.join(\"moderation_logs\", f\"group_13.txt\"), \"a\") as f:\n",
    "            f.write(f\"{time} - {person}: {response.choices[0].message.function_call.arguments}\\n\")\n",
    "\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        with open(os.path.join(\"moderation_logs\", f\"group_1.txt\"), \"a\") as f:\n",
    "            f.write(f\"{time} - {person}: {text}\\n\")\n",
    "\n",
    "    doc = Document(\n",
    "        page_content=text,\n",
    "        metadata={\n",
    "            \"time\": time,\n",
    "            \"person\": person,\n",
    "        },\n",
    "    )\n",
    "    vector_store.add_documents([doc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = create_vector_store()\n",
    "\n",
    "file = group_files[0]\n",
    "\n",
    "with open(os.path.join(txt_path, file), \"r\") as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "for line in text:\n",
    "    time, person, text = split_text(line)\n",
    "\n",
    "    doc = Document(\n",
    "        page_content=text,\n",
    "        metadata={\n",
    "            \"time\": time,\n",
    "            \"person\": person,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    vector_store.add_documents([doc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Vector Store"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
